---
title: "dnaPipeTE.Rmd"
author: "V. MÃ©rel"
date: "19 juillet 2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
```

# Data

## Download or Concatenate

```{bash, eval=F}
scp ~/DTN/INFO.csv merel@pbil-deb:/beegfs/data/merel/DTN #10/08/21

conda activate DTN
conda install -c bioconda sra-tools

cd /beegfs/data/merel/DTN
rm -r /beegfs/data/merel/DTN/Reads/Raw
mkdir /beegfs/data/merel/DTN/Reads/Raw

Samples=`awk -F,  '$12!="NA"' /beegfs/data/merel/DTN/INFO.csv | cut -f 1 -d ','`
#There is 77 samples of known GS
echo $Samples | wc
#      1      77     746

rm -r /beegfs/data/merel/DTN/Reads/Raw
mkdir /beegfs/data/merel/DTN/Reads/Raw
Public=`awk -F,  '$12!="NA"' /beegfs/data/merel/DTN/INFO.csv | grep 'Public' | cut -f 1 -d ','`
echo $Public | wc
Private=`awk -F,  '$12!="NA"' /beegfs/data/merel/DTN/INFO.csv | grep 'Private' | cut -f 1 -d ','`
echo $Private | wc

for Sample in $Samples
do

  echo ''
  echo ''
  echo ''
  echo '################################'
  echo '#'$Sample'#'
  echo '################################'
  echo ''
  
  Info=`awk -F , \
  -v Sample=$Sample \
  ' $1 == Sample { print; } ' \
  /beegfs/data/merel/DTN/INFO.csv`
  
    #Download or Concatenate
  if [[ "$Info" = *"SRR"* ]] || [[ "$Info" = *"DRR"* ]] || [[ "$Info" = *"ERR"* ]]
    then

    SRR=`echo $Info | cut -f 9 -d ','`

    echo '#!/bin/bash
#SBATCH --job-name='"$Sample"'
#SBATCH --partition=normal
#SBATCH --time=06:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem=8G
#SBATCH --output=/beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.out
#SBATCH --error=/beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.err

echo $HOSTNAME

date

rm /beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.fastq.gz

cd /beegfs/data/merel/DTN/Reads/Raw/

sleep $(( RANDOM/300 ))

/beegfs/home/merel/sratoolkit.2.11.0-ubuntu64/bin/fasterq-dump \
--outfile /beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.fastq \
--split-spot \
--threads 8 \
--skip-technical \
'"$SRR"'

gzip /beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.fastq

' > /beegfs/data/merel/DTN/Reads/Raw/$Sample.sh

    else
    
    echo '#!/bin/bash
#SBATCH --job-name='"$Sample"'
#SBATCH --partition=normal
#SBATCH --time=06:00:00
#SBATCH --cpus-per-task=1
#SBATCH --mem=1G
#SBATCH --output=/beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.out
#SBATCH --error=/beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.err

date

rm /beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.fastq.gz

cd /beegfs/data/merel/DTN/Reads/Raw/

if [ -z "$(ls /beegfs/data/haudry/fly_genomes/raw_reads/'"$Sample"'*)" ]
then
  ls /beegfs/data/haudry/fly_genomes/raw_reads/*'"$Sample"'* #ToCheck if everything is OK
  cat /beegfs/data/haudry/fly_genomes/raw_reads/*'"$Sample"'* > /beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.fastq.gz
else
  ls /beegfs/data/haudry/fly_genomes/raw_reads/'"$Sample"'* #ToCheck if everything is OK
  cat /beegfs/data/haudry/fly_genomes/raw_reads/'"$Sample"'* > /beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.fastq.gz
fi
  
' > /beegfs/data/merel/DTN/Reads/Raw/$Sample.sh

  fi
  
  
done



Public=`awk -F,  '$12!="NA"' /beegfs/data/merel/DTN/INFO.csv | grep 'Public' | cut -f 1 -d ','`
echo $Public | wc

for Sample in $Public
do
  sbatch /beegfs/data/merel/DTN/Reads/Raw/$Sample.sh
done
#
Private=`awk -F,  '$12!="NA"' /beegfs/data/merel/DTN/INFO.csv | grep 'Private' | cut -f 1 -d ','`
echo $Private | wc

for Sample in $Private
do
  echo $Sample
  sbatch /beegfs/data/merel/DTN/Reads/Raw/$Sample.sh
done

echo '#!/bin/bash
#SBATCH --job-name=Dathabasca
#SBATCH --partition=normal
#SBATCH --time=12:00:00
#SBATCH --cpus-per-task=2
#SBATCH --mem=2G
#SBATCH --output=/beegfs/data/merel/DTN/Reads/Raw/Dathabasca.out
#SBATCH --error=/beegfs/data/merel/DTN/Reads/Raw/Dathabasca.err

date

rm /beegfs/data/merel/DTN/Reads/Raw/Dathabasca.fastq.gz

cd /beegfs/data/merel/DTN/Reads/Raw/

cat /beegfs/data/haudry/fly_genomes/raw_reads/*athabasca* > /beegfs/data/merel/DTN/Reads/Raw/Dathabasca.fastq.gz' > /beegfs/data/merel/DTN/Reads/Raw/Dathabasca.sh

echo '#!/bin/bash
#SBATCH --job-name=Dmauritiana
#SBATCH --partition=normal
#SBATCH --time=24:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem=8G
#SBATCH --output=/beegfs/data/merel/DTN/Reads/Raw/Dmauritiana.out
#SBATCH --error=/beegfs/data/merel/DTN/Reads/Raw/Dmauritiana.err

echo $HOSTNAME

date

rm /beegfs/data/merel/DTN/Reads/Raw/Dmauritiana.fastq.gz

cd /beegfs/data/merel/DTN/Reads/Raw/

/beegfs/home/merel/sratoolkit.2.11.0-ubuntu64/bin/fasterq-dump \
--outfile /beegfs/data/merel/DTN/Reads/Raw/Dmauritiana.fastq \
--split-spot \
--threads 8 \
--skip-technical \
SRR556206

gzip /beegfs/data/merel/DTN/Reads/Raw/Dmauritiana.fastq' > /beegfs/data/merel/DTN/Reads/Raw/Dmauritiana.sh

sbatch /beegfs/data/merel/DTN/Reads/Raw/Dathabasca.sh
sbatch /beegfs/data/merel/DTN/Reads/Raw/Dmauritiana.sh

# Subpulchrella

echo '#!/bin/bash
#SBATCH --job-name=Dsubp
#SBATCH --partition=normal
#SBATCH --time=06:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem=8G
#SBATCH --output=/beegfs/data/merel/DTN/Reads/Raw/Dsubp.out
#SBATCH --error=/beegfs/data/merel/DTN/Reads/Raw/Dsubp.err

echo $HOSTNAME

date

rm /beegfs/data/merel/DTN/Reads/Raw/Dsubp.fastq.gz

cd /beegfs/data/merel/DTN/Reads/Raw/

sleep $(( RANDOM/300 ))

/beegfs/home/merel/sratoolkit.2.11.0-ubuntu64/bin/fasterq-dump \
--outfile /beegfs/data/merel/DTN/Reads/Raw/Dsubp.fastq \
--split-spot \
--threads 8 \
--skip-technical \
SRR12476582

gzip /beegfs/data/merel/DTN/Reads/Raw/Dsubp.fastq

' > /beegfs/data/merel/DTN/Reads/Raw/Dsubp.sh
```

## Processing 

```{bash, eval=F}
rm /beegfs/data/merel/DTN/Reads/Q*/*
rm -r /beegfs/data/merel/DTN/Reads/Processing
mkdir /beegfs/data/merel/DTN/Reads/Processing

#Samples=`ls /beegfs/data/merel/DTN/Reads/Raw/*fastq.gz | xargs -n 1 basename | cut -f 1 -d '.'`
Samples="Dsubp"

for Sample in $Samples
do

  echo ''
  echo ''
  echo ''
  echo '################################'
  echo '#'$Sample'#'
  echo '################################'
  echo ''

  
  echo '#!/bin/bash
#SBATCH --job-name='"$Sample"'
#SBATCH --partition=normal
#SBATCH --time=24:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem=16G
#SBATCH --output=/beegfs/data/merel/DTN/Reads/Processing/'"$Sample"'.out
#SBATCH --error=/beegfs/data/merel/DTN/Reads/Processing/'"$Sample"'.err

#Q
date

eval "$(conda shell.bash hook)"
conda activate DTN

gzip -cd /beegfs/data/merel/DTN/Reads/Raw/'"$Sample"'.fastq.gz |\
fastq_quality_filter \
-o /beegfs/data/merel/DTN/Reads/Q/'"$Sample"'.fastq.gz \
-Q33 \
-q 20 \
-p 80 \
-z' > /beegfs/data/merel/DTN/Reads/Processing/$Sample.sh

  echo '
  
#fastx_trimmer
date

gzip -cd /beegfs/data/merel/DTN/Reads/Q/'"$Sample"'.fastq.gz |\
fastx_trimmer -f 1 \
-l 74 \
-o /beegfs/data/merel/DTN/Reads/QL/'"$Sample"'.fastq.gz \
-Q33 \
-z

rm /beegfs/data/merel/DTN/Reads/Q/'"$Sample"'.fastq.gz' >> /beegfs/data/merel/DTN/Reads/Processing/$Sample.sh

  echo '
  
#kraken
date

/beegfs/home/merel/kraken2/kraken2 \
--db /beegfs/data/merel/kraken2/bacteria \
--classified-out /beegfs/data/merel/DTN/Reads/QLB/'"$Sample"'.classified.fastq \
--unclassified-out /beegfs/data/merel/DTN/Reads/QLB/'"$Sample"'.unclassified.fastq \
--threads 8 \
--gzip-compressed \
/beegfs/data/merel/DTN/Reads/QL/'"$Sample"'.fastq.gz > /beegfs/data/merel/DTN/Reads/QLB/'"$Sample"'.kraken2

gzip /beegfs/data/merel/DTN/Reads/QLB/'"$Sample"'.kraken2
gzip /beegfs/data/merel/DTN/Reads/QLB/'"$Sample"'.classified.fastq
gzip /beegfs/data/merel/DTN/Reads/QLB/'"$Sample"'.unclassified.fastq

rm /beegfs/data/merel/DTN/Reads/QL/'"$Sample"'.fastq.gz' >> /beegfs/data/merel/DTN/Reads/Processing/$Sample.sh


done

Scripts=`ls /beegfs/data/merel/DTN/Reads/Processing/*.sh | head -n 40`

for Script in $Scripts
do
  sbatch $Script
done

Scripts=`ls /beegfs/data/merel/DTN/Reads/Processing/*.sh | head -n 77 | tail -n 37`

for Script in $Scripts
do
  sbatch $Script
done

#16

ls *fastq


sbatch /beegfs/data/merel/DTN/Reads/Processing/Dsubp.sh 
```

# Run

```{bash, eval=F}
mkdir /beegfs/data/merel/DTN/dnaPipeTE/

#Samples=`ls /beegfs/data/merel/DTN/Reads/QLB/*unclassified.fastq.gz | xargs -n 1 basename | cut -f 1 -d '.'`

echo 'Dsubp, Drosophila subpulchrella, NA, NA, NA, NA, NA, NA, NA , NA ,NA, 322.74, Nelly, NA, NA' >>  /beegfs/data/merel/DTN/INFO.csv

Samples="Dsubp"

for Sample in $Samples
do

  echo ''
  echo ''
  echo ''
  echo '################################'
  echo '#'$Sample'#'
  echo '################################'
  echo ''

  
  echo '#!/bin/bash
#SBATCH --job-name='"$Sample"'
#SBATCH --partition=normal
#SBATCH --time=48:00:00
#SBATCH --cpus-per-task=8
#SBATCH --mem=16G
#SBATCH --output=/beegfs/data/merel/DTN/dnaPipeTE/'"$Sample"'.out
#SBATCH --error=/beegfs/data/merel/DTN/dnaPipeTE/'"$Sample"'.err

#dnaPipeTE
date

#conda
eval "$(conda shell.bash hook)"
conda activate DTN
cd /beegfs/home/merel/dnaPipeTE

export JAVA_HOME=$here/bin/OpenJDK-1.8.0.141-x86_64-bin
export export PATH="$JAVA_HOME/bin:$PATH"

GS=`awk -F ,  '\'' $1 == "'"$Sample"'" { print$12 } '\''   /beegfs/data/merel/DTN/INFO.csv`
GS=`printf '%.0f' $GS`
GS=${GS}000000

for i in {1..3}
do
  
  rm -r /beegfs/data/merel/DTN/dnaPipeTE/'"$Sample"'_$i
  mkdir /beegfs/data/merel/DTN/dnaPipeTE/'"$Sample"'_$i
  
  python3 ./dnaPipeTE.py \
-input /beegfs/data/merel/DTN/Reads/QLB/'"$Sample"'.unclassified.fastq.gz \
-output /beegfs/data/merel/DTN/dnaPipeTE/'"$Sample"'_$i \
-genome_size $GS \
-genome_coverage 0.15 \
-sample_number 2 \
-cpu 8

done

conda deactivate' > /beegfs/data/merel/DTN/dnaPipeTE/$Sample.sh

sbatch /beegfs/data/merel/DTN/dnaPipeTE/$Sample.sh
done



```


# Get Results

```{bash, eval=F}
rm -r /home/vincent/DTN/dnaPipeTE
mkdir /home/vincent/DTN/dnaPipeTE

rsync -rav -e ssh --include '*/' --include='Counts.txt' --exclude='*' \
merel@pbil-deb:/beegfs/data/merel/DTN/dnaPipeTE/* \
/home/vincent/DTN/dnaPipeTE/

cd /home/vincent/DTN/dnaPipeTE/

```

# Synthetize

```{r, eval=F}
library(stringr)
###############Initialization of table###############
Counts <- read.delim(
  paste(
    "/home/vincent/DTN/dnaPipeTE/affinis_1/Counts.txt",
    sep=""),
  header=FALSE,
  comment.char="#")

colnames(Counts)<-c("Categ","Reads")

Counts <- tidyr::spread(Counts,Categ,Reads)

Counts$TotalRepeated <- sum(Counts[,1:14])
Counts$TotalRepeatedPerc <- sum(Counts[,1:14])/Counts[,15]*100
Counts$Id <- "affinis"
Counts$Rep <- 1
#Removing row(s)
Counts <- Counts[-1,]
######################################################


#########################Test#########################
for (Species in list.files(path =
                          "/home/vincent/DTN/dnaPipeTE/",
                          pattern="_1",
                          full.names = FALSE,
                          recursive = FALSE)) {
  
  Species=str_sub(Species,1,nchar(Species)-2)
  print(Species)
  
  for (replicate in 1:3){
    
    print(replicate)
    
    CountsTemp <- read.delim(
      paste("/home/vincent/DTN/dnaPipeTE/",Species,"_",replicate,"/Counts.txt",sep=""),
      header=FALSE,
      comment.char="#")
    
    colnames(CountsTemp)<-c("Categ","Reads")
    
    CountsTemp <- tidyr::spread(CountsTemp,Categ,Reads)
    
    CountsTemp$TotalRepeated <- sum(CountsTemp[,1:14])
    CountsTemp$TotalRepeatedPerc <- sum(CountsTemp[,1:14])/CountsTemp[,15]*100
    CountsTemp$Id <- Species
    CountsTemp$Rep <- replicate
    
    Counts <- rbind(Counts,CountsTemp)
  }
}
####################################################  

plop <- Counts %>% dplyr::select(-c("Total","TotalRepeated","TotalRepeatedPerc"))
plop

#Removing non TE categories
#plop <- plop %>% select(-c("Low_Complexity","rRNA","Satellite","Simple_repeat","Tandem_repeats"))

#Removing empty categories
#sum(plop$MITE)
#sum(plop$Others)
#plop <- plop %>% select(-c("MITE","Others"))

#plop <- Counts %>% select("DNA","Helitron","LINE","LTR","ID","Rep")
#plop <- plop %>% mutate(DNA=DNA+Helitron) %>%  select("DNA","LINE","LTR","ID","Rep")
#plop <- plop %>% mutate(Tot=DNA+LINE+LTR, Rep=Rep)

plop <- plop %>% tidyr::gather("Categ","Nbp",c(1:14))
plop$Nbp=plop$Nbp/0.15

#Removing empty categories
plop %>% dplyr::group_by(Categ) %>% dplyr::summarize(Sum=sum(Nbp))
plop <- subset(plop, !(Categ %in% c("MITE","Others","Tandem_repeats")))
#head(Counts)
#test <- Counts %>% tidyr::gather("Categ","Nbp",c(1:14))
#ggplot(test, aes(x=ID, y=Nbp, fill=Categ))+geom_bar(stat="identity")+facet_grid(.~Rep)

write.table(plop, "/home/vincent/DTN/dnaPipeTE/results.synth.txt")

```

# GS

```{r, eval=F}
#Importing Tables
Info <- read.csv("~/DTN/INFO.csv", header=FALSE)
colnames(Info)=c("Id",
                 "sp.",
                 "-",
                 "PP",
                 "New",
                 "Assembly",
                 "Assembly_Sample",
                 "Reads_Sample",
                 "Reads",
                 "Reads_Size",
                 "Female Male",
                 "GS",
                 "GS_Source",
                 "Tip",
                 "Dev")

Info <- Info[!is.na(Info$GS),]

dnaPipeTE <- read.csv("/home/vincent/DTN/dnaPipeTE/results.synth.txt", sep="")
head(dnaPipeTE)

#d
df <- dplyr::left_join(Info, dnaPipeTE,by="Id")

#colnames(df)[12]="id"
#length(levels(df$ID))

#df <- df %>% tidyr::complete(Id, Categ)
#df <- df[!is.na(df$Categ),]

#Add a total level
#Add a TE level

df <- df %>% group_by(Id, Categ, GS) %>% summarize(Nbp=median(Nbp))

df$Categ=as.character(df$Categ)

for (i in levels(df$Id)){
  
  
  All = subset(df, Id==i) 
  
  rows <- df[0,]

  rows[1,"Id"]=i
  rows[1,"Categ"]="Total"
  rows[1,"Nbp"]=sum(All$Nbp)
  rows[1,"GS"]=All$GS[1]

  TEs = All %>% filter (Categ %in% c("DNA", "Helitron", "LINE", "LTR","SINE")) 
  rows[2,"Id"]=i
  rows[2,"Categ"]="TE"
  rows[2,"Nbp"]=sum(TEs$Nbp)
  rows[2,"GS"]=TEs$GS[1]
  
  df <- rbind(df,rows)
  }
df$Categ=as.factor(df$Categ)


library(ggpubr)
ggscatter(df,
          x = "Nbp",
          y = "GS",
          add = "reg.line",
          scales = "free",
          facet.by = "Categ", #scales = "free_x",
          )+
  stat_cor(method = "pearson", label.x = 3, label.y = 30)

X <- df$Nbp[df$Categ=="TE" & df$Id!="Dsuzukii" & df$Id!="dvir"]
X = X/1000000
Y <- df$GS[df$Categ=="TE"& df$Id!="Dsuzukii" & df$Id!="dvir" ] 
lm = lm(Y~X)
summary(lm)
plot(X,Y)
```

## PIC

```{r, eval=F}
df <- df[!is.na(df$Categ),]
to_sort <- df[df$Categ=="TE",c(1,11,15)]


library(ggtree)
tree <- read.tree("/home/vincent/DTN/Tree/root_droso_tree_MF")
Sorter=tree$tip.label

sorted = to_sort[match(Sorter, to_sort$Id),]


library(ape)

tree <- read.tree("/home/vincent/DTN/Tree/root_droso_tree_MF")

sorted <- sorted[!is.na(sorted$GS),]
X <- sorted$Nbp
Y <- sorted$GS
names(X) <- names(Y) <- sorted$Id

tree <-  drop.tip(tree, c("Dnigromelanica",
                          "Dathabasca",
                          "Dlowei",
                          "madeirensis",
                          "Drhopaloa"))
pic.X <- pic(X, tree)
pic.Y <- pic(Y, tree)
cor.test(pic.X, pic.Y)
test <- lm(pic.Y ~ pic.X - 1) # both regressions
lm(pic.X ~ pic.Y - 1) # through the origin
unlink("ex.tre") # delete the file "ex.tre"

plop <- data.frame(Nbp=pic.X,
                   GS=pic.Y)

ggscatter(plop,
          x = "Nbp",
          y = "GS",
          add = "reg.line",
          scales = "free",
          )+
  stat_cor(method = "pearson", label.x = -1e8, label.y = 500)

tr <- read.tree(text = "(A:1,(B:1,(C:1,(D:1,E:1):1):1):1):1;")
plot(tr)
tr1 <- drop.tip(tr, c("A", "B"), root.edge = 0) # = (C:1,(D:1,E:1):1);
plot(tr1)
tr1 <- drop.tip(tr, c("A", "B"), root.edge = 1) # = (C:1,(D:1,E:1):1):1;
plot(tr1)
drop.tip(tr1, c("A", "B"), root.edge = 2) # = (C:1,(D:1,E:1):1):2;
plot(tr1)
drop.tip(tr1, c("A", "B"), root.edge = 3) # = (C:1,(D:1,E:1):1):3;
plot(tr1)
```

# GS-Dev

```{r, eval=F}
#Importing Tables
Info <- read.csv("~/DTN/INFO.csv", header=FALSE)
colnames(Info)=c("Id",
                    "sp.",
                    "-",
                    "PP",
                    "Assembly",
                    "Assembly_Sample",
                    "Reads_Sample",
                    "Reads",
                    "Female Male",
                    "GS",
                    "GS_Source",
                 "Tip",
                 "Dev")



library(ggpubr)
ggscatter(Info,
          x = "GS",
          y = "Dev",
          add = "reg.line",
          scales = "free")+
  stat_cor(method = "pearson", label.x = 150, label.y = 27.5)

shapiro.test(Info$GS)
shapiro.test(Info$Dev)
```


## PIC

```{r, eval=F}
X <- Info$GS[!is.na(Info$Dev) & !is.na(Info$GS)]
Y <- Info$Dev[!is.na(Info$Dev)  & !is.na(Info$GS)]
names(X) <- names(Y) <- Info$Id[!is.na(Info$Dev)  & !is.na(Info$GS)]

library(ape)

tree <- read.tree("/home/vincent/DTN/Tree/root_droso_tree_MF")


tree <-  drop.tip(tree, as.character(Info$Id[is.na(Info$Dev)  | is.na(Info$GS)]))

pic.X <- pic(X, tree)
pic.Y <- pic(Y, tree)
cor.test(pic.X, pic.Y)
test <- lm(pic.Y ~ pic.X - 1) # both regressions
lm(pic.X ~ pic.Y - 1) # through the origin
unlink("ex.tre") # delete the file "ex.tre"

plop <- data.frame(Dev=pic.Y,
                   GS=pic.X)

ggscatter(plop,
          x = "GS",
          y = "Dev",
          add = "reg.line",
          scales = "free",
          )+
  stat_cor(method = "pearson", label.x = 0, label.y = 30)

```